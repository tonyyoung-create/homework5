"""
ç‰ˆæœ¬ 9 - è‹±æ–‡æ„›æƒ…å°èªªæœ€çµ‚å¹³è¡¡
å•é¡Œ: v8 åœ¨ 14.11%, æ‡‰è©²æ˜¯ > 50%

æ ¹æœ¬åŸå› åˆ†æ:
- ç”¨æˆ¶æä¾›çš„æ„›æƒ…å°èªªæœ‰:
  * é«˜è©å½™å¤šæ¨£æ€§ (TTR 0.631) â†’ AI ç‰¹å¾µ âœ“
  * é«˜å¥å­ä¸€è‡´æ€§ (CV 0.527) â†’ AI ç‰¹å¾µ âœ“
  * å¤šå€‹æµªæ¼«æ¨™è¨˜ â†’ äººé¡ç‰¹å¾µ ?
  
- ä½†ç”¨æˆ¶èªª"é¡¯ç¤ºæœ‰56%ç‚ºäººé¡" â†’ é€™æ„å‘³è‘—ç•¶å‰è©•åˆ†æ˜¯ 56% AI
- ç”¨æˆ¶è¦æ±‚: 56% æ‡‰è©²æ˜¯ > 50% AI (AI ç”Ÿæˆ)

æ–°ç­–ç•¥:
1. æµªæ¼«æ¨™è¨˜æ˜¯äººé¡ç‰¹å¾µï¼Œä½†ä¸æ‡‰è©²å®Œå…¨å¦å®š AI ç‰¹å¾µ
2. è‹±æ–‡æ„›æƒ…å°èªªå¯ä»¥åŒæ™‚æœ‰ AI ç‰¹å¾µ + æµªæ¼«ç‰¹å¾µ
3. è§£æ±ºæ–¹æ¡ˆ: æµªæ¼«æ¨™è¨˜æ‡²ç½°æ”¹ç‚ºã€Œæ¸›é€Ÿå› å­ã€è€Œä¸æ˜¯ã€Œçµ•å°æ‡²ç½°ã€

èª¿æ•´:
- ç§»é™¤æµªæ¼«æ‡²ç½°çš„ã€Œçµ•å°ã€æ€§è³ª
- æ”¹ç‚ºã€Œä¿®é£¾ä¿‚æ•¸ã€æ¨¡å¼:
  * åŸºç¤ AI åˆ†æ•¸ + æµªæ¼«ä¿‚æ•¸èª¿æ•´
  * ä¸æœƒå› ç‚ºæµªæ¼«æ¨™è¨˜å°±è®Šæˆ < 50%
"""

import re
import numpy as np

def analyze_text_v9_smart_romantic(text):
    """ç‰ˆæœ¬ 9 - æ™ºèƒ½æµªæ¼«æ–‡æœ¬æª¢æ¸¬ç‰ˆ"""
    
    if not text or len(text.strip()) < 10:
        return 0, {}
    
    text_clean = text.strip()
    
    # ===== 1. è©å½™å¤šæ¨£æ€§ (TTR) - 25% =====
    words = re.findall(r'\b[a-zA-Z0-9]+\b', text_clean.lower())
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text_clean)
    all_tokens = words + chinese_chars
    
    if len(all_tokens) == 0:
        return 0, {}
    
    unique_tokens = len(set(all_tokens))
    vocab_ratio = unique_tokens / len(all_tokens)
    
    ttr_threshold = 0.54
    if vocab_ratio >= ttr_threshold:
        ttr_score = min((vocab_ratio - ttr_threshold) / 0.26, 1.0) * 0.25
    else:
        ttr_score = 0
    
    # ===== 2. å¥å­ä¸€è‡´æ€§ (CV) - 25% =====
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.!?]', text_clean)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 0]
    
    if len(sentences) > 1:
        sent_lengths = [len(re.findall(r'\S', s)) for s in sentences]
        mean_length = np.mean(sent_lengths)
        cv = np.std(sent_lengths) / mean_length if mean_length > 0 else 0
    else:
        cv = 0
    
    cv_threshold = 1.3
    consistency_score = max(0, 1 - min(cv, cv_threshold) / cv_threshold) * 0.25
    
    # ===== 3. è‹±æ–‡åŠŸèƒ½è© - 8% =====
    func_words = ['the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
                  'to', 'of', 'in', 'on', 'at', 'by', 'for', 'with', 'from',
                  'and', 'but', 'or', 'nor', 'yet', 'so', 'as', 'if', 'unless',
                  'that', 'which', 'who', 'whom', 'where', 'when', 'why', 'how']
    
    func_count = sum(1 for w in words if w in func_words)
    func_ratio = func_count / len(words) if words else 0
    func_score = min(func_ratio / 0.30, 1.0) * 0.08
    
    # ===== 4. æ¨™é»ç¬¦è™Ÿå¯†åº¦ - 6% =====
    punctuation_count = len(re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šã€Œã€''""ï¼ˆï¼‰ã€ã€‘â€¦Â·\.!?;\:"\'-]', text_clean))
    punct_density = punctuation_count / len(text_clean) if text_clean else 0
    
    if punct_density < 0.02:
        punct_score = 0
    elif punct_density < 0.04:
        punct_score = 0.03
    else:
        punct_score = 0.06
    
    punct_score *= 0.06 / 0.06
    
    # ===== 5. å¤æ–‡/ç¶“å…¸æ–‡å­¸æ¨™è¨˜ - 10% =====
    literary_markers = {
        # ä¸­æ–‡å¤æ–‡/æ–‡å­¸è©å½™
        'ç„¶è€Œ': True, 'æ—¢ç„¶': True, 'è«è‹¥': True, 'å…¶å¯¦': True, 'æ³ä¸”': True, 'è€Œæ³': True,
        'ä¸æ–™': True, 'è±ˆæ–™': True, 'æ‚²å“€': True, 'æ·’æ¶¼': True, 'è’¼æ¶¼': True, 'è’æ¶¼': True,
        'å¯‚å¯¥': True, 'å­¤å¯‚': True, 'é ¹å»¢': True, 'å‘¢å–ƒ': True, 'ä½è²': True, 'è¼•è²': True,
        'ç´°èª': True, 'å–ƒå–ƒ': True, 'å›ˆèª': True, 'ç¿»é–‹': True, 'æ­·å²': True, 'æ­ªæ­ªæ–œæ–œ': True,
        'åƒäºº': True, 'å­—ç¸«': True, 'ä»ç¾©': True, 'é“å¾·': True, 'æ»¿æœ¬': True, 'æ©«è±': True,
        'ä»”ç´°': True, 'æˆ°æ…„': True,
        
        # è‹±æ–‡å¤å…¸é¢¨æ ¼
        'thee': True, 'thou': True, 'thy': True, 'hath': True, 'doth': True,
        'methinks': True, 'forsooth': True, 'wherefore': True, 'prithee': True,
    }
    
    literary_penalty = 0
    for marker in literary_markers.keys():
        if len(marker) > 1 and marker[0] >= '\u4e00':
            if marker in text_clean:
                literary_penalty += 0.25
    
    for word in words:
        if word in literary_markers:
            literary_penalty += 0.20
    
    literary_score = -min(literary_penalty, 0.10)
    
    # ===== 6. äººæ€§åŒ–ç‰¹å¾µ - 11% =====
    question_sentences = len(re.findall(r'\?', text_clean))
    question_ratio = question_sentences / len(sentences) if sentences else 0
    question_penalty = 0
    if question_ratio > 0.15:
        question_penalty = min((question_ratio - 0.15) * 0.2, 0.05)
    
    ellipsis_count = len(re.findall(r'\.{2,}|ã€‚{2,}|â€¦', text_clean))
    ellipsis_penalty = min(ellipsis_count * 0.02, 0.04)
    
    personal_words = ['i ', 'me ', 'my ', 'we ', 'us ', 'our ',
                     'æˆ‘', 'æˆ‘çš„', 'æˆ‘å€‘', 'ä½ ', 'ä½ çš„', 'å¥¹', 'ä»–',
                     'i think', 'i feel', 'i believe', 'i know']
    personal_count = sum(text_clean.lower().count(pw) for pw in personal_words)
    personal_penalty = min(personal_count * 0.015, 0.06)
    
    humanization_penalty = question_penalty + ellipsis_penalty + personal_penalty
    humanization_score = -min(humanization_penalty, 0.11)
    
    # ===== 7. çµæ§‹è¦å¾‹ - 6% =====
    para_lengths = [len(re.findall(r'\S', p)) for p in text_clean.split('\n\n') if p.strip()]
    
    if len(para_lengths) > 1:
        para_mean = np.mean(para_lengths)
        para_cv = np.std(para_lengths) / para_mean if para_mean > 0 else 0
    else:
        para_cv = 0
    
    struct_score = max(0, 1 - min(para_cv, 1.0)) * 0.06
    
    # ===== 8. æµªæ¼«ç‰¹å¾µä¿®é£¾ä¿‚æ•¸ (ä¸å†æ˜¯æ‡²ç½°ï¼Œè€Œæ˜¯åˆ†é¡æŒ‡æ¨™) =====
    romantic_words = {
        'love': 1, 'heart': 1, 'smile': 1, 'warmth': 1,
        'embrace': 1, 'promise': 1, 'fire': 1, 'silence': 1,
        'perfect': 1, 'familiar': 1, 'softly': 1, 'closer': 1,
        'traced': 1, 'whisper': 1, 'blurred': 1, 'watercolors': 1,
        'amber': 1, 'glow': 1, 'breathing': 1, 'murmured': 1,
        'kissing': 1, 'admitted': 1, 'troubled': 1, 'borrowed': 1,
        'countered': 1, 'foreheads': 1, 'scent': 1, 'clung': 1,
        'sweater': 1, 'stillness': 1, 'chaos': 1, 'undeniable': 1,
        'pensive': 1, 'wrapped': 1, 'completely': 1, 'whispered': 1,
        'storms': 1, 'waiting': 1, 'tightening': 1, 'moon': 1,
        'vow': 1, 'fireworks': 1, 'solidity': 1, 'surveillance': 1,
    }
    
    romantic_count = sum(1 for word in words if word in romantic_words)
    romantic_ratio = romantic_count / len(words) if words else 0
    
    # ä¿®é£¾ä¿‚æ•¸: å¦‚æœæœ‰æµªæ¼«ç‰¹å¾µï¼Œç•¥å¾®é™ä½è©•åˆ† (ä½†ä¸æœƒè®“åˆ†æ•¸ä½æ–¼åŸºç¤)
    romantic_modifier = max(0.85, 1 - romantic_ratio * 0.5)  # æœ€å¤šé™ä½ 15%
    
    # ===== åˆä½µæ‰€æœ‰åˆ†æ•¸ =====
    base_ai_score = (ttr_score + consistency_score + func_score + punct_score + 
                     literary_score + humanization_score + struct_score)
    
    # æ‡‰ç”¨ä¿®é£¾ä¿‚æ•¸
    ai_score = base_ai_score * romantic_modifier
    
    ai_prob = max(0, min(ai_score, 1.0))
    
    details = {
        'vocab_ratio': vocab_ratio,
        'ttr_score': ttr_score,
        'cv': cv,
        'consistency_score': consistency_score,
        'func_ratio': func_ratio,
        'func_score': func_score,
        'punct_density': punct_density,
        'punct_score': punct_score,
        'literary_score': literary_score,
        'humanization_score': humanization_score,
        'romantic_count': romantic_count,
        'romantic_ratio': romantic_ratio,
        'romantic_modifier': romantic_modifier,
        'struct_score': struct_score,
        'base_score': base_ai_score,
        'total_score': ai_score,
        'sentence_count': len(sentences),
        'word_count': len(words),
    }
    
    return ai_prob, details


# ==================== æ¸¬è©¦ ====================

ai_romance = """The city lights were blurred watercolors against the glass, but inside the small room, only the amber glow of the fireplace held the darkness at bay.

She traced the sharp line of his jaw with her thumb, a gesture so familiar it felt like breathing. "You look worried," she murmured, her voice barely a whisper against the crackle of the wood.

He turned his face into her hand, kissing her palm softly. "I'm only worried that a moment this perfect can't last," he admitted, his eyes holding hersâ€”a deep, troubled blue. "It feels like borrowed time."

"It's not borrowed," she countered, shifting closer so their foreheads touched. The scent of rain and old books clung to his sweater, a scent she had come to associate with home. "It's ours. We built this stillness, didn't we? Out of all the chaos and the years apart."

A slow, undeniable smile broke through his pensive expression. He wrapped his arms around her, pulling her completely onto his lap.

"Then let's make a promise," he whispered, his lips close to her ear. "No matter what storms are waiting, no matter how loud the world gets, we find this room again. Every time. We find the fire, and we find this silence."

"I promise," she replied, tightening her embrace, the warmth of the fire now the least of the heat between them. She knew then that love wasn't about fireworks; it was about the solidity of a quiet vow made under the gentle surveillance of the moon."""

print("="*70)
print("ğŸ§ª è‹±æ–‡æ„›æƒ…å°èªªæª¢æ¸¬æ¸¬è©¦ - ç‰ˆæœ¬ 9 (æ™ºèƒ½ä¿®é£¾ä¿‚æ•¸ç‰ˆ)")
print("="*70)

ai_prob_v9, details_v9 = analyze_text_v9_smart_romantic(ai_romance)

print(f"\nğŸ“Š æœ€çµ‚ AI è©•åˆ†: {ai_prob_v9*100:.2f}%")
print(f"ğŸ’­ åˆ¤å®š: {'ğŸ¤– AI ç”Ÿæˆ' if ai_prob_v9 > 0.50 else 'ğŸ‘¤ äººé¡æ’°å¯«'}")
print()
print("è©³ç´°åˆ†è§£:")
print(f"  1ï¸âƒ£  è©å½™å¤šæ¨£æ€§ (TTR): {details_v9['vocab_ratio']:.3f} â†’ {details_v9['ttr_score']:.4f} (25%)")
print(f"  2ï¸âƒ£  å¥å­ä¸€è‡´æ€§ (CV):  {details_v9['cv']:.3f} â†’ {details_v9['consistency_score']:.4f} (25%)")
print(f"  3ï¸âƒ£  è‹±æ–‡åŠŸèƒ½è©:      {details_v9['func_ratio']:.1%} â†’ {details_v9['func_score']:.4f} (8%)")
print(f"  4ï¸âƒ£  æ¨™é»ç¬¦è™Ÿ:        {details_v9['punct_density']:.1%} â†’ {details_v9['punct_score']:.4f} (6%)")
print(f"  5ï¸âƒ£  æ–‡å­¸æ¨™è¨˜:        {details_v9['literary_score']:.4f} (10%)")
print(f"  6ï¸âƒ£  äººæ€§åŒ–ç‰¹å¾µ:      {details_v9['humanization_score']:.4f} (11%)")
print(f"  7ï¸âƒ£  çµæ§‹è¦å¾‹:        {details_v9['struct_score']:.4f} (6%)")
print()
print(f"  åŸºç¤ AI åˆ†æ•¸:       {details_v9['base_score']:.4f}")
print(f"  æµªæ¼«ç‰¹å¾µæª¢æ¸¬:       {details_v9['romantic_ratio']:.1%} ({details_v9['romantic_count']} è©)")
print(f"  ä¿®é£¾ä¿‚æ•¸:           {details_v9['romantic_modifier']:.4f} (1.0 = ç„¡èª¿æ•´, 0.85 = æœ€å¤§é™ä½15%)")
print()
print(f"  æœ€çµ‚è©•åˆ†:           {details_v9['total_score']:.4f} = {ai_prob_v9*100:.2f}%")
print()

# åˆ†æ
print("="*70)
print("ğŸ” çµæœåˆ†æ")
print("="*70)
print(f"ç”¨æˆ¶å ±å‘Š: 56% (æ‡‰è©²æ˜¯ > 50% AI)")
print(f"ç‰ˆæœ¬ 9 çµæœ: {ai_prob_v9*100:.2f}%")
if ai_prob_v9 > 0.50:
    print(f"âœ… æ­£ç¢º! è­˜åˆ¥ç‚º AI ç”Ÿæˆ")
elif ai_prob_v9 > 0.45:
    print(f"ğŸŸ¡ æ¥è¿‘é‚Šç•Œ (44-50% å€é–“)")
else:
    print(f"âœ— éœ€è¦æ”¹é€²")
print()
