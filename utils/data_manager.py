"""
ç”Ÿæˆèˆ‡ç®¡ç†è¨“ç·´ã€é©—è­‰æ•¸æ“šé›†
"""

import json
import csv
from pathlib import Path
from typing import List, Dict

# çœŸå¯¦ Human æ–‡æœ¬æ¨£æœ¬
HUMAN_SAMPLES = [
    "ä½ çŸ¥é“å—Žï¼Ÿæˆ‘ä»Šå¤©åœ¨è·¯ä¸Šçœ‹åˆ°ä¸€éš»è¶…å¤§çš„çƒé´‰ï¼ŒçœŸçš„æ˜¯è¶…æ‰¯ã€‚è€Œä¸”ç‰ é‚„æ¶èµ°æˆ‘æœ‹å‹çš„ä¾¿ç•¶ï¼Œå“ˆå“ˆå“ˆã€‚ç„¶å¾Œæœ‹å‹å°±å¾ˆç”Ÿæ°£ï¼Œè¿½è‘—çƒé´‰è·‘äº†ä¸€æ•´æ¢è¡—ã€‚å¤ªæ‰¯äº†ã€‚",
    
    "å—¯å…¶å¯¦æˆ‘è¦ºå¾—é€™å€‹æ–¹æ¡ˆæœ‰é»žå•é¡Œå•¦ã€‚é¦–å…ˆæˆæœ¬å¤ªé«˜ï¼Œå…¶æ¬¡å¯¦è¡Œå›°é›£ã€‚ä½†å¦‚æžœæ”¹ä¸€ä¸‹çš„è©±æ‡‰è©²é‚„æœ‰æ•‘ã€‚ä¸éŽè¦çœ‹è€é—†åŒä¸åŒæ„å°±æ˜¯äº†ã€‚çœŸçš„æ˜¯é ­ç—›è€¶â€¦â€¦",
    
    "å‰›å‰›æœ‰å€‹æœƒè­°è¶…ç„¡èŠæ¬¸ã€‚é‚£å€‹äººä¸€ç›´åœ¨è¬›å»¢è©±ï¼Œæˆ‘æ•´å€‹äººå¿«ç¡è‘—äº†ã€‚æœ€å¾Œé‚„è¢«è€é—†é»žåå›žç­”å•é¡Œï¼Œæˆ‘å®Œå…¨æ²’åœ¨è½ ðŸ˜­ å°·å°¬åˆ°çˆ†ç‚¸ã€‚",
    
    "AI ç¾åœ¨çœŸçš„å¾ˆåŽ²å®³æ¬¸ï¼ä½†æˆ‘é‚„æ˜¯æœ‰é»žæ€•å®ƒæœƒæ¶èµ°æˆ‘å€‘çš„å·¥ä½œå•¦ã€‚ä¸éŽè©±èªªå›žä¾†ï¼Œä¹Ÿæ»¿ä¾¿åˆ©çš„å°±æ˜¯ï¼Œå¾ˆå¤šäº‹æƒ…éƒ½å¯ä»¥äº¤çµ¦å®ƒåšã€‚æ„Ÿè¦ºæ˜¯é›™é¢åˆƒå§ã€‚",
    
    "å¤©å•Šï¼æˆ‘æ˜¨å¤©æ™šä¸Šç†¬å¤œçœ‹åŠ‡ï¼Œæ—©ä¸Šèµ·ä¸ä¾†ï¼Œé²åˆ°äº† 20 åˆ†é˜ã€‚çµæžœè¢«ä¸»ç®¡ç½µåˆ°è‡­é ­ã€‚çœŸçš„è¶…å¾Œæ‚”å•¦ï¼Œä»¥å¾Œå†ä¹Ÿä¸ç†¬å¤œäº†â€¦â€¦ï¼ˆæ‰æ€ªï¼‰",
    
    "æ¬¸ä½ æœ‰æ²’æœ‰çœ‹åˆ°æ–°èžï¼Ÿèªªåœ‹å¤–é‚£é‚Šåˆç™¼ç”Ÿä»€éº¼äº‹æƒ…ã€‚æˆ‘è¦ºå¾—ç¾åœ¨çš„ä¸–ç•ŒçœŸçš„æœ‰é»žäº‚æ¬¸ã€‚ä¸éŽæˆ‘ä¹Ÿæ‡¶å¾—ä¸€å€‹ä¸€å€‹åŽ»äº†è§£ï¼Œå°±çœ‹çœ‹æœ‰æ²’æœ‰äººä¾†è·Ÿæˆ‘è¬›ã€‚",
    
    "æˆ‘æœ€è¿‘åœ¨å­¸ Pythonï¼Œä½†æ˜¯çœŸçš„è¶…é›£çš„å•¦ï¼ä¸€å †æ¦‚å¿µéƒ½æžä¸æ‡‚ï¼Œæ¯æ¬¡å¯«ç¨‹å¼éƒ½æœƒå‡ºç¾ä¸€å † errorã€‚æ°£æ­»äº†ã€‚ä¸éŽæœ‰æ™‚å€™æˆåŠŸåŸ·è¡Œçš„æ™‚å€™é‚„æ»¿æœ‰æˆå°±æ„Ÿçš„å•¦ã€‚",
]

# AI ç”Ÿæˆæ–‡æœ¬æ¨£æœ¬ï¼ˆæ¨¡æ“¬ ChatGPT / GPT-3.5 ç­‰æ¨¡åž‹çš„è¼¸å‡ºï¼‰
AI_SAMPLES = [
    "Artificial intelligence represents a paradigm shift in how we approach problem-solving. Machine learning algorithms have demonstrated remarkable capabilities across diverse domains, from natural language processing to computer vision. The integration of deep learning techniques has enabled systems to achieve performance levels previously thought impossible. As AI continues to evolve, it is crucial to consider both the opportunities and challenges it presents to society.",
    
    "The implementation of modern cloud infrastructure has revolutionized data management practices. Organizations can now leverage scalable computing resources to process vast amounts of information efficiently. This technological advancement facilitates real-time analytics and enables businesses to make data-driven decisions more effectively. Furthermore, the adoption of cloud-based solutions reduces operational costs while improving system reliability and accessibility.",
    
    "The field of renewable energy is experiencing significant growth as global awareness of climate change increases. Solar and wind power technologies have become increasingly cost-effective and efficient. Government incentives and corporate investments are accelerating the transition toward sustainable energy sources. This shift not only addresses environmental concerns but also creates new economic opportunities in the clean energy sector.",
    
    "Cybersecurity has become an essential component of modern business operations. As digital threats continue to evolve, organizations must implement comprehensive security measures to protect their systems and data. The adoption of multi-factor authentication, encryption protocols, and regular security audits helps mitigate potential vulnerabilities. Training employees on security best practices remains a critical element in maintaining a robust security posture.",
    
    "Digital transformation initiatives have fundamentally altered the landscape of contemporary business. Organizations that successfully implement digital strategies gain competitive advantages through improved efficiency and customer engagement. The integration of artificial intelligence, cloud computing, and big data analytics enables companies to optimize their operations and deliver enhanced value to stakeholders. As technology continues to advance, the pace of digital transformation is expected to accelerate further.",
    
    "The application of machine learning techniques in healthcare has demonstrated considerable promise in improving diagnostic accuracy and treatment outcomes. Predictive models can identify disease patterns and risk factors, enabling healthcare professionals to intervene proactively. The analysis of large medical datasets facilitates the discovery of novel therapeutic approaches and personalized medicine strategies. However, the implementation of these technologies requires careful consideration of ethical implications and data privacy concerns.",
    
    "E-commerce platforms have transformed consumer shopping behavior and retail business models. The convenience of online shopping, combined with personalized recommendations powered by machine learning algorithms, has significantly increased customer engagement. Supply chain optimization through data analytics ensures efficient inventory management and timely product delivery. These technological innovations have created unprecedented opportunities for businesses to expand their market reach and enhance customer satisfaction.",
]

# ä¸­æ–‡ç‰ˆæœ¬
HUMAN_SAMPLES_CN = [
    "å¤©å•¦ï¼Œæˆ‘ä»Šå¤©åœ¨èª²å ‚ä¸Šå®Œå…¨æ²’è½èª²ï¼Œè€å¸«ä¸€ç›´åœ¨è¬›ä»€éº¼æˆ‘æ ¹æœ¬ä¸çŸ¥é“ã€‚è€Œä¸”é‚„è¢«é»žåå›žç­”å•é¡Œï¼Œæˆ‘åªèƒ½èªªä¸çŸ¥é“ã€‚è¶…å°·å°¬çš„å•¦â€¦â€¦ä¸‹æ¬¡ä¸€å®šè¦èªçœŸè½ã€‚ï¼ˆé¨™äººï¼‰",
    
    "é€™å€‹æ¡ˆå­çœŸçš„å¾ˆè¤‡é›œæ¬¸ã€‚é¦–å…ˆå®¢æˆ¶çš„éœ€æ±‚ä¸€ç›´åœ¨è®Šï¼Œå…¶æ¬¡æˆ‘å€‘çš„æŠ€è¡“å¯èƒ½ä¸è¶³ä»¥æ‡‰å°ã€‚ä½†åæ­£å°±å…ˆè©¦è©¦çœ‹å§ï¼Œæ­»é¦¬ç•¶æ´»é¦¬é†«ã€‚å¸Œæœ›ä¸è¦å‡ºå¤ªå¤§çš„å•é¡Œå•¦ã€‚",
    
    "æ˜¨å¤©ç†¬å¤œæ‰“éŠæˆ²ï¼Œä»Šå¤©ä¸Šç­è¶…ç´¯ã€‚ä¸€æ•´å¤©éƒ½åœ¨æ‰“å“ˆæ¬ ï¼ŒåŒäº‹é‚„å•æˆ‘æ˜¯ä¸æ˜¯ç”Ÿç—…äº†å“ˆå“ˆã€‚çœŸçš„è¦æ”¹æŽ‰é€™å€‹å£žç¿’æ…£â€¦â€¦ä½†éŠæˆ²å¤ªå¥½çŽ©äº†å•¦ï¼",
    
    "ç¾åœ¨çš„ AI åŠ©æ‰‹çœŸçš„å¾ˆå¼·æ¬¸ï¼Œå¯ä»¥å¹«æˆ‘å¯«æ–‡æ¡ˆã€å¯«ç¨‹å¼ã€ç”šè‡³å¯«ä½œæ¥­ã€‚ä¸éŽç¸½è¦ºå¾—æœ‰é»žæ€ªæ€ªçš„ï¼Œæ„Ÿè¦ºæœ‰é»žå¤ªç°¡å–®äº†ï¼Ÿä½†åˆä¸èƒ½æ‹’çµ•é€™ç¨®ä¾¿åˆ©å•¦ã€‚",
]

AI_SAMPLES_CN = [
    "äººå·¥æ™ºæ…§æŠ€è¡“æ­£åœ¨é€æ­¥æ”¹è®Šäººé¡žç¤¾æœƒçš„å„å€‹é ˜åŸŸã€‚é€šéŽæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’ç®—æ³•çš„æ‡‰ç”¨ï¼Œç³»çµ±å¯ä»¥å¯¦ç¾è‡ªå‹•åŒ–æ±ºç­–å’Œæ™ºèƒ½åˆ†æžã€‚è‡ªç„¶èªžè¨€è™•ç†çš„é€²æ­¥ä½¿å¾—äººæ©Ÿäº¤äº’è®Šå¾—æ›´åŠ è‡ªç„¶æµæš¢ã€‚éš¨è‘—æŠ€è¡“çš„ä¸æ–·æ¼”é€²ï¼Œæˆ‘å€‘å¯ä»¥é æœŸäººå·¥æ™ºæ…§å°‡åœ¨æœªä¾†ç™¼æ®è¶Šä¾†è¶Šé‡è¦çš„ä½œç”¨ã€‚",
    
    "æ•¸å­—åŒ–è½‰åž‹å·²æˆç‚ºç¾ä»£ä¼æ¥­ç™¼å±•çš„å¿…ç„¶è¶¨å‹¢ã€‚çµ„ç¹”é€šéŽæ•´åˆé›²è¨ˆç®—ã€å¤§æ•¸æ“šåˆ†æžå’Œç‰©è¯ç¶²æŠ€è¡“ï¼Œèƒ½å¤ é¡¯è‘—æå‡é‹ç‡Ÿæ•ˆçŽ‡å’Œæ±ºç­–è³ªé‡ã€‚é€™äº›æŠ€è¡“çš„æ‡‰ç”¨ä¸åƒ…é™ä½Žäº†æˆæœ¬ï¼Œé‚„å‰µé€ äº†æ–°çš„å•†æ¥­æ©Ÿé‡ã€‚ä¼æ¥­éœ€è¦å»ºç«‹å®Œå–„çš„æ•¸å­—æˆ°ç•¥ä»¥é©æ‡‰ä¸æ–·è®ŠåŒ–çš„å¸‚å ´ç’°å¢ƒã€‚",
    
    "å¯å†ç”Ÿèƒ½æºç”¢æ¥­æ­£é¢è‡¨å‰æ‰€æœªæœ‰çš„ç™¼å±•æ©Ÿé‡ã€‚å¤ªé™½èƒ½å’Œé¢¨èƒ½æŠ€è¡“æˆæœ¬çš„ä¸‹é™ä½¿å…¶è¶Šä¾†è¶Šå…·æœ‰ç«¶çˆ­åŠ›ã€‚æ”¿åºœæ”¿ç­–æ”¯æŒå’Œä¼æ¥­æŠ•è³‡çš„å¢žåŠ åŠ é€Ÿäº†èƒ½æºçµæ§‹çš„èª¿æ•´ã€‚é€™ç¨®è½‰è®Šæ—¢æ‡‰å°äº†ç’°å¢ƒæŒ‘æˆ°ï¼Œä¹Ÿç‚ºç¶“æ¿Ÿç™¼å±•å¸¶ä¾†äº†æ–°çš„å¢žé•·é»žã€‚",
    
    "ç¶²çµ¡å®‰å…¨å·²æˆç‚ºä¼æ¥­ä¿¡æ¯ç®¡ç†çš„æ ¸å¿ƒè¦ç´ ã€‚éš¨è‘—å¨è„…çš„ä¸æ–·æ¼”è®Šï¼Œçµ„ç¹”å¿…é ˆæŽ¡å–å…¨é¢çš„å®‰å…¨æŽªæ–½ä¿è­·ç³»çµ±å’Œæ•¸æ“šã€‚å¯¦æ–½å¤šå› ç´ èªè­‰ã€åŠ å¯†å”è­°å’Œå®šæœŸå®‰å…¨å¯©è¨ˆæœ‰åŠ©æ–¼é™ä½Žæ½›åœ¨é¢¨éšªã€‚å“¡å·¥å®‰å…¨æ„è­˜åŸ¹è¨“æ˜¯ç¶­æŒå¼·å¤§å®‰å…¨é˜²è­·çš„é—œéµã€‚",
]


def create_dataset(output_path: str = 'data/training_data.csv', language: str = 'english'):
    """
    å»ºç«‹è¨“ç·´æ•¸æ“šé›†
    
    Args:
        output_path: è¼¸å‡º CSV æª”æ¡ˆè·¯å¾‘
        language: 'english' æˆ– 'chinese'
    """
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    if language == 'english':
        human_texts = HUMAN_SAMPLES
        ai_texts = AI_SAMPLES
    else:
        human_texts = HUMAN_SAMPLES_CN
        ai_texts = AI_SAMPLES_CN
    
    data = []
    
    # æ·»åŠ  Human æ¨£æœ¬
    for text in human_texts:
        data.append({'text': text, 'label': 0})  # 0 = Human
    
    # æ·»åŠ  AI æ¨£æœ¬
    for text in ai_texts:
        data.append({'text': text, 'label': 1})  # 1 = AI
    
    # å¯«å…¥ CSV
    with open(output_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['text', 'label'])
        writer.writeheader()
        writer.writerows(data)
    
    print(f"Dataset created: {output_path}")
    print(f"Total samples: {len(data)} (Human: {len(human_texts)}, AI: {len(ai_texts)})")


def create_json_dataset(output_path: str = 'data/training_data.json', language: str = 'english'):
    """
    å»ºç«‹ JSON æ ¼å¼çš„æ•¸æ“šé›†
    
    Args:
        output_path: è¼¸å‡º JSON æª”æ¡ˆè·¯å¾‘
        language: 'english' æˆ– 'chinese'
    """
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    if language == 'english':
        human_texts = HUMAN_SAMPLES
        ai_texts = AI_SAMPLES
    else:
        human_texts = HUMAN_SAMPLES_CN
        ai_texts = AI_SAMPLES_CN
    
    data = {
        'human': [{'text': text, 'label': 0} for text in human_texts],
        'ai': [{'text': text, 'label': 1} for text in ai_texts],
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"JSON dataset created: {output_path}")


def load_dataset(dataset_path: str) -> List[Dict]:
    """
    è¼‰å…¥æ•¸æ“šé›†
    
    Args:
        dataset_path: æ•¸æ“šé›†æª”æ¡ˆè·¯å¾‘
        
    Returns:
        æ•¸æ“šåˆ—è¡¨
    """
    data = []
    
    if dataset_path.endswith('.csv'):
        with open(dataset_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append({
                    'text': row['text'],
                    'label': int(row['label'])
                })
    elif dataset_path.endswith('.json'):
        with open(dataset_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
            if isinstance(raw_data, dict):
                data = raw_data.get('human', []) + raw_data.get('ai', [])
            else:
                data = raw_data
    
    return data


if __name__ == "__main__":
    # å»ºç«‹è‹±æ–‡æ•¸æ“šé›†
    create_dataset('data/training_data_en.csv', language='english')
    create_json_dataset('data/training_data_en.json', language='english')
    
    # å»ºç«‹ä¸­æ–‡æ•¸æ“šé›†
    create_dataset('data/training_data_cn.csv', language='chinese')
    create_json_dataset('data/training_data_cn.json', language='chinese')
    
    # æ¸¬è©¦è¼‰å…¥
    data = load_dataset('data/training_data_en.csv')
    print(f"\nLoaded {len(data)} samples from CSV")
